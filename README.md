---

# ğŸš€ Jetson Thor Multimodal VLM Drone Agent
![Image](https://github.com/user-attachments/assets/679b9c90-3d9d-4a4f-91d6-3f6800cc0548)
### ğŸ¤– Conversational Drone with Edge AI + Vision-Language Model (VLM)

This project demonstrates a **fully interactive multimodal drone** powered by **Jetson Thor** and the **Qwen2.5-VL-32B-Instruct-AWQ** model using **vLLM** and **ROS2**.
It enables the drone to **see, understand, and respond** in natural language â€” combining **computer vision**, **ROS2 robotics**, and **Edge AI**.

---

## ğŸ§  System Overview
<img width="1536" height="1024" alt="Image" src="https://github.com/user-attachments/assets/9044c195-c67b-40fd-911e-5595f27e4449" />
The architecture connects multiple components:

```
Web Interface â†” ROSBridge â†” ROS2 Nodes â†” VLM Server (Qwen2.5-VL)
```

âœ… Web interface for interaction
âœ… ROS2 bridge for communication
âœ… VLM model for visual-language reasoning
âœ… Real-time drone perception and response

---

## âš™ï¸ Launching the System

Run each component in a **separate terminal** for smooth operation.

---

### **1ï¸âƒ£ Start ROSBridge (WebSocket Interface)**

Allows the web client to communicate with ROS2 topics:

```bash
ros2 launch rosbridge_server rosbridge_websocket_launch.xml
```

---

### **2ï¸âƒ£ Start Camera Bridge**

Converts simulation or real camera feed for web streaming:

```bash
ros2 run vlm_ros2_package simple_camera_bridge
```

---

### **3ï¸âƒ£ Start the VLM Client Node**

Handles text queries and responses between the ROS2 system and the VLM model:

```bash
ros2 run vlm_ros2_package vlm_client_node
```

---

### **4ï¸âƒ£ Start the Web Interface**

Opens a browser-based control and visualization dashboard:

```bash
cd ~/ros2_ws/src/vlm_ros2_package/web_interface
python app.py
```

Then open your browser and go to:

ğŸ‘‰ [http://localhost:5000](http://localhost:5000)

---

### **5ï¸âƒ£ Start the VLLM Vision-Language Model Server**

Run the **Qwen2.5-VL-32B-Instruct-AWQ** model with vLLM:

```bash
./run_vllm_vlm_serve.sh Qwen/Qwen2.5-VL-32B-Instruct-AWQ
```

---

## âœ… System Ready!

Once all terminals are running:

ğŸ§© The drone can:

* Observe the environment through the camera
* Understand visual scenes
* Respond to queries naturally
* Enable real-time human-drone interaction

---

## ğŸ–¼ï¸ System Diagram

```text
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      Web Interface       â”‚
          â”‚  (User Query & Display)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              WebSocket / REST
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      ROSBridge Server   â”‚
          â”‚ (Connects Web â†” ROS2)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                ROS2 Topics / Nodes
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  VLM Client Node        â”‚
          â”‚ (Text â†” Vision Queries) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                   HTTP / API
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   vLLM Server (Qwen2.5) â”‚
          â”‚  Vision-Language Model  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Jetson Thor Drone   â”‚
          â”‚ (Camera + Control Unit) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Repository Structure

```
Jetson-Thor-Multimodal-VLM-Robot-Agent/
â”‚
â”œâ”€â”€ ros2_ws/
â”‚   â””â”€â”€ src/vlm_ros2_package/
â”‚       â”œâ”€â”€ simple_camera_bridge.py
â”‚       â”œâ”€â”€ vlm_client_node.py
â”‚       â””â”€â”€ web_interface/
â”‚           â””â”€â”€ app.py
â”‚
â”œâ”€â”€ run_vllm_vlm_serve.sh
â””â”€â”€ README.md
```

---

## ğŸ§© Technologies Used

* **NVIDIA Jetson Thor**
* **ROS2 Humble**
* **vLLM (for fast LLM inference)**
* **Qwen2.5-VL-32B-Instruct-AWQ**
* **Python + Flask Web Interface**
* **WebSocket + ROSBridge**

---

## ğŸ§  Reference Blog

For a detailed explanation and implementation steps, check out the full article on Medium:
ğŸ“– [Conversational Drones: Integrating Vision-Language Models on Jetson Thor for Edge AI](https://medium.com/@kabilankb2003/conversational-drones-integrating-vision-language-models-on-jetson-thor-for-edge-ai-1fae287a01dd)

---
